{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 개선된 CBOW모델 구현\n",
    "- input -> W로 전달되는 부분의 효율적인 학습을 구현한 **Embedding**층을 적용하고\n",
    "- h -> out(loss)로 전달되는 부분의 효과적인 학습을 구현한 **Negative Sampling**계층을 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from mh_common.mh_layers import Embedding\n",
    "sys.path.append(r'C:\\Users\\kang_lp\\OneDrive - UOS\\bitamin\\dl_nlp_study\\deep-learning-from-scratch-2-master')\n",
    "\n",
    "from ch04.negative_sampling_layer import NegativeSamplingLoss\n",
    "\n",
    "class CBOW:\n",
    "    def __init__(self, vocab_size, hidden_size, window_size, corpus):\n",
    "        V, H = vocab_size, hidden_size\n",
    "        \n",
    "        #가중치 초기화\n",
    "        W_in = 0.01 * np.random.randn(V,H).astype('f')\n",
    "        W_out = 0.01 * np.random.randn(V,H).astype('f')\n",
    "        \n",
    "        #계층 생성\n",
    "        self.in_layers = []\n",
    "        for i in range(2 * window_size):\n",
    "            layer = Embedding(W_in)\n",
    "            self.in_layers.append(layer)\n",
    "        self.ns_loss = NegativeSamplingLoss(W_out, corpus, power = 0.75, sample_size = 5)\n",
    "        \n",
    "        #모든 가중치와 기울기를 []안에 모으는 작업\n",
    "        layers = self.in_layers + [self.ns_loss] #기존 in_layer리스트 안에 self.ns_loss의 객체들을 추가하는 것\n",
    "        self.params, self.grads = [], []\n",
    "        for layer in layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "        \n",
    "        #단어의 분산 표현을 저장\n",
    "        self.word_vecs = W_in\n",
    "        \n",
    "    def forward(self, contexts, target):\n",
    "        #contexts는 target을 둘러싸는 window단어들의 단어ID를 담은 행렬\n",
    "        h = 0\n",
    "        for i, layer in enumerate(self.in_layers):\n",
    "            h += layer.forward(contexts[:, i])\n",
    "        h *= 1 / len(self.in_layers)\n",
    "        loss = self.ns_loss.forward(h, target)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout = 1):\n",
    "        dout = self.ns_loss.backward(dout)\n",
    "        dout *= 1 / len(self.in_layers)\n",
    "        for layer in self.in_layers:\n",
    "            layer.backward(dout)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | mini-batch 1 / 9295 | 시간 0[s] |avg_loss 4.16\n",
      "| epoch 1 | mini-batch 21 / 9295 | 시간 2[s] |avg_loss 4.16\n",
      "| epoch 1 | mini-batch 41 / 9295 | 시간 3[s] |avg_loss 4.15\n",
      "| epoch 1 | mini-batch 61 / 9295 | 시간 5[s] |avg_loss 4.13\n",
      "| epoch 1 | mini-batch 81 / 9295 | 시간 7[s] |avg_loss 4.05\n",
      "| epoch 1 | mini-batch 101 / 9295 | 시간 8[s] |avg_loss 3.93\n",
      "| epoch 1 | mini-batch 121 / 9295 | 시간 10[s] |avg_loss 3.79\n",
      "| epoch 1 | mini-batch 141 / 9295 | 시간 12[s] |avg_loss 3.63\n",
      "| epoch 1 | mini-batch 161 / 9295 | 시간 14[s] |avg_loss 3.50\n",
      "| epoch 1 | mini-batch 181 / 9295 | 시간 15[s] |avg_loss 3.37\n",
      "| epoch 1 | mini-batch 201 / 9295 | 시간 17[s] |avg_loss 3.24\n",
      "| epoch 1 | mini-batch 221 / 9295 | 시간 19[s] |avg_loss 3.17\n",
      "| epoch 1 | mini-batch 241 / 9295 | 시간 20[s] |avg_loss 3.10\n",
      "| epoch 1 | mini-batch 261 / 9295 | 시간 22[s] |avg_loss 3.02\n",
      "| epoch 1 | mini-batch 281 / 9295 | 시간 24[s] |avg_loss 2.98\n",
      "| epoch 1 | mini-batch 301 / 9295 | 시간 25[s] |avg_loss 2.92\n",
      "| epoch 1 | mini-batch 321 / 9295 | 시간 27[s] |avg_loss 2.87\n",
      "| epoch 1 | mini-batch 341 / 9295 | 시간 29[s] |avg_loss 2.85\n",
      "| epoch 1 | mini-batch 361 / 9295 | 시간 31[s] |avg_loss 2.83\n",
      "| epoch 1 | mini-batch 381 / 9295 | 시간 33[s] |avg_loss 2.80\n",
      "| epoch 1 | mini-batch 401 / 9295 | 시간 34[s] |avg_loss 2.75\n",
      "| epoch 1 | mini-batch 421 / 9295 | 시간 36[s] |avg_loss 2.77\n",
      "| epoch 1 | mini-batch 441 / 9295 | 시간 38[s] |avg_loss 2.75\n",
      "| epoch 1 | mini-batch 461 / 9295 | 시간 40[s] |avg_loss 2.72\n",
      "| epoch 1 | mini-batch 481 / 9295 | 시간 41[s] |avg_loss 2.68\n",
      "| epoch 1 | mini-batch 501 / 9295 | 시간 43[s] |avg_loss 2.67\n",
      "| epoch 1 | mini-batch 521 / 9295 | 시간 45[s] |avg_loss 2.66\n",
      "| epoch 1 | mini-batch 541 / 9295 | 시간 46[s] |avg_loss 2.67\n",
      "| epoch 1 | mini-batch 561 / 9295 | 시간 48[s] |avg_loss 2.64\n",
      "| epoch 1 | mini-batch 581 / 9295 | 시간 50[s] |avg_loss 2.65\n",
      "| epoch 1 | mini-batch 601 / 9295 | 시간 51[s] |avg_loss 2.65\n",
      "| epoch 1 | mini-batch 621 / 9295 | 시간 53[s] |avg_loss 2.66\n",
      "| epoch 1 | mini-batch 641 / 9295 | 시간 55[s] |avg_loss 2.62\n",
      "| epoch 1 | mini-batch 661 / 9295 | 시간 56[s] |avg_loss 2.63\n",
      "| epoch 1 | mini-batch 681 / 9295 | 시간 58[s] |avg_loss 2.60\n",
      "| epoch 1 | mini-batch 701 / 9295 | 시간 60[s] |avg_loss 2.62\n",
      "| epoch 1 | mini-batch 721 / 9295 | 시간 62[s] |avg_loss 2.59\n",
      "| epoch 1 | mini-batch 741 / 9295 | 시간 63[s] |avg_loss 2.60\n",
      "| epoch 1 | mini-batch 761 / 9295 | 시간 65[s] |avg_loss 2.61\n",
      "| epoch 1 | mini-batch 781 / 9295 | 시간 67[s] |avg_loss 2.60\n",
      "| epoch 1 | mini-batch 801 / 9295 | 시간 68[s] |avg_loss 2.61\n",
      "| epoch 1 | mini-batch 821 / 9295 | 시간 70[s] |avg_loss 2.58\n",
      "| epoch 1 | mini-batch 841 / 9295 | 시간 72[s] |avg_loss 2.60\n",
      "| epoch 1 | mini-batch 861 / 9295 | 시간 73[s] |avg_loss 2.57\n",
      "| epoch 1 | mini-batch 881 / 9295 | 시간 75[s] |avg_loss 2.56\n",
      "| epoch 1 | mini-batch 901 / 9295 | 시간 77[s] |avg_loss 2.56\n",
      "| epoch 1 | mini-batch 921 / 9295 | 시간 79[s] |avg_loss 2.60\n",
      "| epoch 1 | mini-batch 941 / 9295 | 시간 81[s] |avg_loss 2.57\n",
      "| epoch 1 | mini-batch 961 / 9295 | 시간 83[s] |avg_loss 2.58\n",
      "| epoch 1 | mini-batch 981 / 9295 | 시간 85[s] |avg_loss 2.56\n",
      "| epoch 1 | mini-batch 1001 / 9295 | 시간 86[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1021 / 9295 | 시간 88[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1041 / 9295 | 시간 90[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1061 / 9295 | 시간 91[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1081 / 9295 | 시간 93[s] |avg_loss 2.57\n",
      "| epoch 1 | mini-batch 1101 / 9295 | 시간 95[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1121 / 9295 | 시간 97[s] |avg_loss 2.55\n",
      "| epoch 1 | mini-batch 1141 / 9295 | 시간 99[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1161 / 9295 | 시간 101[s] |avg_loss 2.55\n",
      "| epoch 1 | mini-batch 1181 / 9295 | 시간 102[s] |avg_loss 2.57\n",
      "| epoch 1 | mini-batch 1201 / 9295 | 시간 104[s] |avg_loss 2.55\n",
      "| epoch 1 | mini-batch 1221 / 9295 | 시간 106[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1241 / 9295 | 시간 108[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1261 / 9295 | 시간 110[s] |avg_loss 2.56\n",
      "| epoch 1 | mini-batch 1281 / 9295 | 시간 111[s] |avg_loss 2.56\n",
      "| epoch 1 | mini-batch 1301 / 9295 | 시간 113[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1321 / 9295 | 시간 115[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1341 / 9295 | 시간 117[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1361 / 9295 | 시간 118[s] |avg_loss 2.54\n",
      "| epoch 1 | mini-batch 1381 / 9295 | 시간 120[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1401 / 9295 | 시간 122[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1421 / 9295 | 시간 124[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 1441 / 9295 | 시간 126[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1461 / 9295 | 시간 128[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 1481 / 9295 | 시간 129[s] |avg_loss 2.53\n",
      "| epoch 1 | mini-batch 1501 / 9295 | 시간 131[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 1521 / 9295 | 시간 133[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 1541 / 9295 | 시간 135[s] |avg_loss 2.55\n",
      "| epoch 1 | mini-batch 1561 / 9295 | 시간 136[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 1581 / 9295 | 시간 138[s] |avg_loss 2.55\n",
      "| epoch 1 | mini-batch 1601 / 9295 | 시간 140[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1621 / 9295 | 시간 142[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1641 / 9295 | 시간 143[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1661 / 9295 | 시간 145[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 1681 / 9295 | 시간 147[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 1701 / 9295 | 시간 149[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 1721 / 9295 | 시간 150[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1741 / 9295 | 시간 152[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 1761 / 9295 | 시간 154[s] |avg_loss 2.46\n",
      "| epoch 1 | mini-batch 1781 / 9295 | 시간 155[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 1801 / 9295 | 시간 157[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 1821 / 9295 | 시간 159[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 1841 / 9295 | 시간 161[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 1861 / 9295 | 시간 162[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 1881 / 9295 | 시간 164[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 1901 / 9295 | 시간 166[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 1921 / 9295 | 시간 167[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 1941 / 9295 | 시간 169[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 1961 / 9295 | 시간 171[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 1981 / 9295 | 시간 172[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 2001 / 9295 | 시간 174[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2021 / 9295 | 시간 176[s] |avg_loss 2.46\n",
      "| epoch 1 | mini-batch 2041 / 9295 | 시간 177[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2061 / 9295 | 시간 179[s] |avg_loss 2.51\n",
      "| epoch 1 | mini-batch 2081 / 9295 | 시간 181[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2101 / 9295 | 시간 183[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2121 / 9295 | 시간 184[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2141 / 9295 | 시간 186[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 2161 / 9295 | 시간 188[s] |avg_loss 2.46\n",
      "| epoch 1 | mini-batch 2181 / 9295 | 시간 189[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 2201 / 9295 | 시간 191[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 2221 / 9295 | 시간 193[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2241 / 9295 | 시간 194[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 2261 / 9295 | 시간 196[s] |avg_loss 2.52\n",
      "| epoch 1 | mini-batch 2281 / 9295 | 시간 198[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 2301 / 9295 | 시간 200[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2321 / 9295 | 시간 201[s] |avg_loss 2.50\n",
      "| epoch 1 | mini-batch 2341 / 9295 | 시간 203[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2361 / 9295 | 시간 205[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2381 / 9295 | 시간 206[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2401 / 9295 | 시간 208[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2421 / 9295 | 시간 210[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 2441 / 9295 | 시간 211[s] |avg_loss 2.45\n",
      "| epoch 1 | mini-batch 2461 / 9295 | 시간 213[s] |avg_loss 2.45\n",
      "| epoch 1 | mini-batch 2481 / 9295 | 시간 215[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2501 / 9295 | 시간 217[s] |avg_loss 2.44\n",
      "| epoch 1 | mini-batch 2521 / 9295 | 시간 218[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2541 / 9295 | 시간 220[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2561 / 9295 | 시간 222[s] |avg_loss 2.45\n",
      "| epoch 1 | mini-batch 2581 / 9295 | 시간 224[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2601 / 9295 | 시간 225[s] |avg_loss 2.49\n",
      "| epoch 1 | mini-batch 2621 / 9295 | 시간 227[s] |avg_loss 2.43\n",
      "| epoch 1 | mini-batch 2641 / 9295 | 시간 229[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2661 / 9295 | 시간 231[s] |avg_loss 2.45\n",
      "| epoch 1 | mini-batch 2681 / 9295 | 시간 232[s] |avg_loss 2.44\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch 1 | mini-batch 2701 / 9295 | 시간 234[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2721 / 9295 | 시간 236[s] |avg_loss 2.45\n",
      "| epoch 1 | mini-batch 2741 / 9295 | 시간 238[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2761 / 9295 | 시간 239[s] |avg_loss 2.47\n",
      "| epoch 1 | mini-batch 2781 / 9295 | 시간 241[s] |avg_loss 2.48\n",
      "| epoch 1 | mini-batch 2801 / 9295 | 시간 243[s] |avg_loss 2.43\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-11b4a221f5e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;31m#학습시작\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontexts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - UOS\\bitamin\\dl_nlp_study\\mh_common\\mh_trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, t, max_epoch, batch_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m                 \u001b[1;31m#매개변수의 중복값 및 정규화 작업 추가 수행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m                     \u001b[0mclip_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#max_grad가 입력된 경우에만 기울기 정규화 작업을 수행\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - UOS\\bitamin\\dl_nlp_study\\mh_common\\mh_trainer.py\u001b[0m in \u001b[0;36mremove_duplicate\u001b[1;34m(params, grads)\u001b[0m\n\u001b[0;32m     29\u001b[0m                 \u001b[1;31m#가중치를 전치행렬로 공유하는 경우에는 다음과 같이 처리하여라\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;32melif\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m                      \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m                     \u001b[0mfind_flg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mall\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36mall\u001b[1;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[0;32m   2349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2350\u001b[0m     \"\"\"\n\u001b[1;32m-> 2351\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogical_and\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2352\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2353\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpasskwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#CBOW모델 훈련\n",
    "import pickle\n",
    "from common import config\n",
    "from mh_common.mh_trainer import Trainer\n",
    "from mh_common.mh_optimizer import Adam\n",
    "from mh_common.mh_utils import create_contexts_target, to_cpu, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "#하이퍼 파라미터 설정\n",
    "window_size = 5 #윈도우 사이즈가 5, 따라서 입력층이 10(5 * 2)개로 존재하게 됨\n",
    "hidden_size = 100 #100개의 뉴런을 가지는 은닉층\n",
    "batch_size = 100\n",
    "max_epoch = 10 #총 훈련횟수\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "contexts, target = create_contexts_target(corpus, window_size)\n",
    "if config.GPU:\n",
    "    contexts, target = to_gpu(contexts), to_gpu(target)\n",
    "\n",
    "#모델 생성\n",
    "model = CBOW(vocab_size, hidden_size, window_size, corpus)\n",
    "\n",
    "#optimizer 생성\n",
    "optimizer = Adam()\n",
    "trainer = Trainer(model, optimizer)\n",
    "\n",
    "#학습시작\n",
    "trainer.fit(contexts, target, max_epoch, batch_size)\n",
    "trainer.plot()\n",
    "\n",
    "word_vecs = model.word_vecs #분산표현을 모델에 저장\n",
    "if config.GPU:\n",
    "    word_vecs = to_cpu(word_vecs)\n",
    "\n",
    "#학습된 가중치들과 word_to_id, id_to_word를 pkl파일로 저장\n",
    "params = {}\n",
    "params['word_vecs'] = word_vecs.astype(np.float16)\n",
    "params['word_to_id'] = word_to_id\n",
    "params['id_to_word'] = id_to_word\n",
    "pkl_file = 'cbow_param.pkl'\n",
    "with open(pkl_file, 'wb') as f:\n",
    "    pickle.dump(params, f, -1)\n",
    "\n",
    "    #노트북으로는 학습시간이 너무 길어서 작업을 중단함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptb 데이터 형태 살펴보기\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\kang_lp\\OneDrive - UOS\\bitamin\\dl_nlp_study\\deep-learning-from-scratch-2-master')\n",
    "\n",
    "from dataset import ptb\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2, ..., 39, 26, 24])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus #문서의 내용들이 통으로 하나의 문장으로 존재"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "929589"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
