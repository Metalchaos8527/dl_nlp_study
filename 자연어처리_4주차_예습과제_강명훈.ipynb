{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 통계 기반의 텍스트 처리 기법 \n",
    "\n",
    "#말뭉치 전처리 예제\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "\n",
    "#단어 단위로 자르기 위한 순서\n",
    "#1) 모든 글자를 소문자로\n",
    "text = text.lower()\n",
    "\n",
    "#2) 띄어쓰기 기준으로 구분하기 위해 온점을 한칸 띄우기\n",
    "text = text.replace('.', ' .')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'you say goodbye and i say hello .'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['you', 'say', 'goodbye', 'and', 'i', 'say', 'hello', '.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#띄어쓰기 기준으로 문장을 단어로 구분하기\n",
    "words = text.split(' ')\n",
    "words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['You',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'goodbye',\n",
       " ' ',\n",
       " 'and',\n",
       " ' ',\n",
       " 'I',\n",
       " ' ',\n",
       " 'say',\n",
       " ' ',\n",
       " 'hello',\n",
       " '.',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정규표현식을 이용한 범용적인 방법\n",
    "import re\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "\n",
    "re.split(r'(\\W+)', text)\n",
    "    #re.split은 두번째 인자에 들어가는 문자안에서 첫번째 인자를 기준으로 문자들을 구분하여 리스트로 반환하는 기능을 제공한다\n",
    "    # \\W는 문자나 숫자가 아닌 문자열들을 찾는 기능을 담당한다\n",
    "    # 공백이나 온점 . 는 숫자나 문자가 아닌 문자열이므로 \\W에 해당한다\n",
    "    # 마지막으로 +를 이용하여 한개이상의 공백이나 온점이 존재할경우를 기준점으로 삼도록한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#단어 정수인덱싱 작업\n",
    "word_to_id = {} #키가 단어이고 값이 정수인덱싱을 담은 딕셔너리 객체\n",
    "id_to_word = {} #키가 정수인덱싱, 값이 단어인 딕셔너리 객체\n",
    "\n",
    "for word in words:\n",
    "    if word not in word_to_id:\n",
    "        new_id = len(word_to_id)\n",
    "        word_to_id[word] = new_id #키는 단어고 값은 정수 인덱싱 번호, 딕셔너리는 []인덱싱에 키를 사용해서 값을 찾거나 입력할 수 있다\n",
    "        #또 키가 존재하지 않는다면 []로 키를 입력하고 그에 해당하는 값을 할당할 수 있단\n",
    "        id_to_word[new_id] = word #키는 정수인덱싱 번호, 값은 단어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'say'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#정수 인덱싱으로 단어를 검색하는 경우\n",
    "id_to_word[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어로 정수인덱싱을 검색하는 경우\n",
    "word_to_id['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#단어list를 정수인덱싱 리스트로 변환하기\n",
    "import numpy as np\n",
    "\n",
    "corpus = [word_to_id[w] for w in words]\n",
    "corpus = np.array(corpus)\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#텍스트 전처리 + 정수 인덱싱 + 단어id 리스트 반환 사용자정의 함수 만들기\n",
    "#mh_common의 mh_utils.py에 작성함\n",
    "\n",
    "from mh_common.mh_utils import preprocess\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 1, 5, 6])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'you': 0, 'say': 1, 'goodbye': 2, 'and': 3, 'i': 4, 'hello': 5, '.': 6}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_to_word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분포가설\n",
    "- 단어의 의미를 파악하기 위해 사용되는 통계적 기법들의 기본적인 가설\n",
    "- 어떤 단어의 의미는 주변에 있는 단어들의 **맥락**속에서 생성된다\n",
    "- 여기서 맥락은 기준 단어 주변에 존재하는 단어들\n",
    "- 맥락에 해당하는 단어들의 개수는 사용자가 설정하는 하이퍼 파라미터인 **윈도우 크기**에 따라서 결정\n",
    "- 윈도우 크기가 2일 경우 기준 단어를 바탕으로 좌, 우 2개의 단어를 맥락으로 취급한다\n",
    "\n",
    "## 동시발생 행렬\n",
    "- 분포가설에 기반해서 corpus를 분석할 때 어떤 단어 주변에 등장하는 단어들의 등장 빈도를 셀 수 있다\n",
    "- 이렇게 해서 생성된 행렬을 **동시발생 행렬**이라고 한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#윈도우 크기가 1인 경우의 동시발생 행렬\n",
    "\n",
    "C = np.array([\n",
    "    [0, 1, 0, 0, 0, 0, 0],\n",
    "    [1, 0, 1, 0, 1, 1, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 0, 1, 0, 1, 0, 0],\n",
    "    [0, 1, 0, 1, 0, 0, 0],\n",
    "    [0, 1, 0, 0, 0, 0, 1],\n",
    "    [0, 0, 0, 0, 0, 1, 0]   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#create_co_matrix 를 mh_utils.py에 작성\n",
    "from mh_common.mh_utils import create_co_matrix\n",
    "\n",
    "create_co_matrix(corpus, len(id_to_word), 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터간 유사도 (코사인 유사도)\n",
    "\n",
    "## $similarity(x,y) = \\frac{xy}{\\|x\\|\\|y\\|}$\n",
    "- 분자는 두 벡터의 내적\n",
    "- 분모는 두 벡터의 L2-norm 값의 곱\n",
    "- 코사인 유사도는 두 벡터의 방향이 얼마나 같은지를 나타내는 수치\n",
    "- 1에 가까울수록 두 벡터의 방향이 같고\n",
    "- -1에 가까울수록 두 벡터의 방향이 반대이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#코사인 유사도 산출 함수\n",
    "\n",
    "def cos_similarity(x, y):\n",
    "    nx = x / np.sqrt(np.sum(x**2))\n",
    "    ny = y / np.sqrt(np.sum(y**2))\n",
    "    return np.dot(nx, ny)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#그런데 만약 인자 x, y중 0 벡터가 들어오면\n",
    "#0으로 나누는작업을 실행불가\n",
    "#따라서 이를 보완하기 위한 매우 작은수를 더해주는 작업 필요\n",
    "#mh_utils안에 cos_silmilarity 함수 작성함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you 와 i의 유사도를 구하기\n",
    "from mh_common.mh_utils import preprocess, create_co_matrix, cos_similarity\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(word_to_id)\n",
    "\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "c0 = C[word_to_id['you']]\n",
    "c1 = C[word_to_id['i']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071067758832467\n"
     ]
    }
   ],
   "source": [
    "print(cos_similarity(c0, c1))\n",
    "    #i 와 you의 코사인유사도가 약 0.7로 나타남"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[query] you\n",
      " goodbye: 0.7071067758832467\n",
      " i: 0.7071067758832467\n",
      " hello: 0.7071067758832467\n",
      " say: 0.0\n",
      " and: 0.0\n"
     ]
    }
   ],
   "source": [
    "#검색엔진을 구현해보자\n",
    "#어떤 단어가 들어올 때 검색단어와 유사한 단어들을 \n",
    "#코사인 유사도가 높은순으로 출력하는 함수\n",
    "\n",
    "#you와 유사도가 높은 단어들을 출력하는 작업을 실시\n",
    "\n",
    "from mh_common.mh_utils import preprocess, create_co_matrix, cos_similarity, most_similar\n",
    "\n",
    "text = \"You say goodbye and I say hello.\"\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "\n",
    "vocab_size = len(id_to_word)\n",
    "\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "\n",
    "most_similar('you', word_to_id, id_to_word, C, top = 5)\n",
    "    #여기서 등장하는 유사도를 엄밀히 말하자면\n",
    "    #동시행렬 속 행에 해당하는 단어를 둘러싼 단어들의 출현횟수를 바탕으로 산출된것\n",
    "    #즉 query로 질의한 단어와 유사도가 높은 단어들은\n",
    "    #query단어를 구성하는 맥락 단어들을 많이 공유한다는 것"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 빈도 기반의 모델 보완하기\n",
    "## -> 확률의 개념을 도입하기 \n",
    "- 단순 빈도 기반의 모델 속에서는 문장 내 자주 등장하는 단어들의 빈도가 높게 산출됨\n",
    "- 따라서 어떤 단어의 유사도를 확인한다고 할 때 어떤 단어 전 후로 자주 등장하는 단어들이 높은 가중치를 가지게 된다\n",
    "- 그러나 사실 자주 등장하는 단어가 중요한 의미를 가지는 경우는 적음\n",
    "- 따라서 단순 빈도 기반의 데이터 이용을 넘어서는 표현기법 필요\n",
    "\n",
    "## 점별 상호정보량 Pointwise Manual Information(PMI)\n",
    "## $PMI(x,y) = log_{2}\\frac{P(x,y)}{P(x)P(y)}$\n",
    "- 분자는 x,y가 동시에 등장한 확률\n",
    "- 분모는 개별 x,y가 등장한 확률의 곱\n",
    "\n",
    "**동시 발생핼렬을 이용하여 식을 다시 표현하면 다음과 같다**\n",
    "# $PMI(x,y) = log_{2}\\frac{P(x,y)}{P(x)P(y)} = log_{2}\\frac{\\frac{C(x,y)}{N}}{\\frac{C(x)}{N}\\frac{C(y)}{N}} = log_{2}\\frac{C(x,y)N}{C(x)C(y)}$\n",
    "\n",
    "- 그런데 C(x,y), P(x,y)가 0이면 음의 무한대로 발산하므로 값이 출력되지 않는 문제가 발생\n",
    "- 따라서 이를 보완한 PPMI 지표를 이용\n",
    "\n",
    "## 양의 상호정보량 PPMI\n",
    "## $PPMI = max(0, PMI(x,y))$\n",
    "\n",
    "## 번외. TF-IDF 산출식\n",
    "\n",
    "## $idf(d, t) = log(n/(df(t)+1)) + 1$\n",
    "- n은 문서의 개수\n",
    "- df(t)는 t단어의 출현횟수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.sum(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 4, 2, 2, 2, 2, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(C, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 행렬\n",
      "[[0 1 0 0 0 0 0]\n",
      " [1 0 1 0 1 1 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 0 1 0 1 0 0]\n",
      " [0 1 0 1 0 0 0]\n",
      " [0 1 0 0 0 0 1]\n",
      " [0 0 0 0 0 1 0]]\n",
      "--------------------------------------------------\n",
      "PPMI\n",
      "[[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      " [1.807 0.    0.807 0.    0.807 0.807 0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.    1.807 0.    1.807 0.    0.   ]\n",
      " [0.    0.807 0.    1.807 0.    0.    0.   ]\n",
      " [0.    0.807 0.    0.    0.    0.    2.807]\n",
      " [0.    0.    0.    0.    0.    2.807 0.   ]]\n"
     ]
    }
   ],
   "source": [
    "#동시발생 행렬을 PPMI 행렬로 변환하기 \n",
    "import numpy as np\n",
    "from mh_common.mh_utils import preprocess, create_co_matrix, cos_similarity, ppmi\n",
    "\n",
    "text = 'You say goodbye and I say hello.'\n",
    "\n",
    "corpus, word_to_id, id_to_word = preprocess(text)\n",
    "vocab_size = len(id_to_word)\n",
    "C = create_co_matrix(corpus, vocab_size)\n",
    "W = ppmi(C)\n",
    "\n",
    "np.set_printoptions(precision = 3) #행렬의 소수점을 출력할 때 소수셋째점 자리까지 표시\n",
    "print('동시발생 행렬')\n",
    "print(C)\n",
    "print('-'*50)\n",
    "print('PPMI')\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPMI의 문제점\n",
    "- 동시발생 행렬과 다르게 실수형식으로 표현됨\n",
    "- ppmi의 값이 높을수록 단어의 중요도가 높다는 것을 의미\n",
    "- 즉 행 단어에 대응하는 맥락 단어들의 중요도를 알 수 있다\n",
    "- 그러나 PPMI행렬의 차원은 등장하는 유일한 단어들의 개수와 같다\n",
    "- 따라서 문서의 크기가 클수록 PPMI의 차원은 매우 커질 것\n",
    "- 또한 PPMI는 희소행렬이므로 효율성의 문제가 발생\n",
    "\n",
    "**-> 이를 보완하는 기법의 필요** \n",
    "\n",
    "## 차원축소\n",
    "- 차원축소기법은 기존의 행렬의 차원을 축소하면서도\n",
    "- 중요한 데이터의 손실을 최소화하는 축소된 행렬을 생성하는 기법\n",
    "- 이 때 축소된 행렬은 기존의 희소행렬이 아닌 **밀집행렬**형태\n",
    "\n",
    "## 특이값분해 SVD\n",
    "- 실제로 사용할 기법은 Truncated SVD로 축소된 SVD기법을 사용할 것\n",
    "- SVD를 통해서 U, S, Vt가 생성되는데 이 때 S는 원 행렬의 특이값을 나타낸 대각행렬\n",
    "- 특이값이 큰 순서대로 S의 데이터들이 나열되어 있고\n",
    "- 특이값은 곧 해당 축의 중요도를 나타내므로 \n",
    "- 특이값이 큰 것들의 일부만을 사용하면 차원을 줄일 수 있다. n -> p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#특이값 분해 실시\n",
    "\n",
    "U, S, V = np.linalg.svd(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0]\n",
      "[0.    1.807 0.    0.    0.    0.    0.   ]\n",
      "[-1.110e-16  3.409e-01 -1.205e-01 -3.886e-16  0.000e+00 -9.323e-01\n",
      "  8.768e-17]\n"
     ]
    }
   ],
   "source": [
    "print(C[0])\n",
    "print(W[0])\n",
    "print(U[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.110e-16  3.409e-01]\n"
     ]
    }
   ],
   "source": [
    "#2차원으로 줄이고 싶을 때\n",
    "print(U[0, :2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#단어들을 2차원 그래프에 표현하기\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for word, word_id in word_to_id.items():\n",
    "    plt.annotate(word, (U[word_id, 0], U[word_id, 1]))\n",
    "    \n",
    "plt.scatter(U[:, 0], U[:, 1], alpha = 0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTB 데이터셋\n",
    "- 텍스트 데이터 처리 모델의 품질을 측정하기 위한 영어 텍스트 자료\n",
    "- PTB 데이터셋의 구조를 살펴보자 (우리가 지금까지 사용했던 preprocess 함수를 이용하여)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ptb.train.txt ... \n",
      "Done\n",
      "말뭉치 크기: 929589\n",
      "corpus[:30]: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29]\n",
      "\n",
      "id_to_word[0]: aer\n",
      "id_to_word[1]: banknote\n",
      "id_to_word[2]: berlitz\n",
      "\n",
      "word_to_id['car']: 3856\n",
      "word_to_id['happy']: 4428\n",
      "word_to_id['lexus']: 7426\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Users/myunghoon_k/OneDrive - 서울시립대학교/bitamin/dl_nlp_study/deep-learning-from-scratch-2-master')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "\n",
    "print('말뭉치 크기:', len(corpus))\n",
    "print('corpus[:30]:', corpus[:30])\n",
    "print()\n",
    "print('id_to_word[0]:', id_to_word[0])\n",
    "print('id_to_word[1]:', id_to_word[1])\n",
    "print('id_to_word[2]:', id_to_word[2])\n",
    "print()\n",
    "print(\"word_to_id['car']:\", word_to_id['car'])\n",
    "print(\"word_to_id['happy']:\", word_to_id['happy'])\n",
    "print(\"word_to_id['lexus']:\", word_to_id['lexus'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "동시발생 수 계산 ...\n",
      "PPMI 계산 ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\myunghoon_k\\OneDrive - 서울시립대학교\\bitamin\\dl_nlp_study\\mh_common\\mh_utils.py:123: RuntimeWarning: overflow encountered in long_scalars\n",
      "  pmi = np.log2(C[i, j] * N / (S[i]*S[j]) + eps)\n",
      "C:\\Users\\myunghoon_k\\OneDrive - 서울시립대학교\\bitamin\\dl_nlp_study\\mh_common\\mh_utils.py:123: RuntimeWarning: invalid value encountered in log2\n",
      "  pmi = np.log2(C[i, j] * N / (S[i]*S[j]) + eps)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0% 완료\n",
      "2.0% 완료\n",
      "3.0% 완료\n",
      "4.0% 완료\n",
      "5.0% 완료\n",
      "6.0% 완료\n",
      "7.0% 완료\n",
      "8.0% 완료\n",
      "9.0% 완료\n",
      "10.0% 완료\n",
      "11.0% 완료\n",
      "12.0% 완료\n",
      "13.0% 완료\n",
      "14.0% 완료\n",
      "15.0% 완료\n",
      "16.0% 완료\n",
      "17.0% 완료\n",
      "18.0% 완료\n",
      "19.0% 완료\n",
      "20.0% 완료\n",
      "21.0% 완료\n",
      "22.0% 완료\n",
      "23.0% 완료\n",
      "24.0% 완료\n",
      "25.0% 완료\n",
      "26.0% 완료\n",
      "27.0% 완료\n",
      "28.0% 완료\n",
      "29.0% 완료\n",
      "30.0% 완료\n",
      "31.0% 완료\n",
      "32.0% 완료\n",
      "33.0% 완료\n",
      "34.0% 완료\n",
      "35.0% 완료\n",
      "36.0% 완료\n",
      "37.0% 완료\n",
      "38.0% 완료\n",
      "39.0% 완료\n",
      "40.0% 완료\n",
      "41.0% 완료\n",
      "42.0% 완료\n",
      "43.0% 완료\n",
      "44.0% 완료\n",
      "45.0% 완료\n",
      "46.0% 완료\n",
      "47.0% 완료\n",
      "48.0% 완료\n",
      "49.0% 완료\n",
      "50.0% 완료\n",
      "51.0% 완료\n",
      "52.0% 완료\n",
      "53.0% 완료\n",
      "54.0% 완료\n",
      "55.0% 완료\n",
      "56.0% 완료\n",
      "57.0% 완료\n",
      "58.0% 완료\n",
      "59.0% 완료\n",
      "60.0% 완료\n",
      "61.0% 완료\n",
      "62.0% 완료\n",
      "63.0% 완료\n",
      "64.0% 완료\n",
      "65.0% 완료\n",
      "66.0% 완료\n",
      "67.0% 완료\n",
      "68.0% 완료\n",
      "69.0% 완료\n",
      "70.0% 완료\n",
      "71.0% 완료\n",
      "72.0% 완료\n",
      "73.0% 완료\n",
      "74.0% 완료\n",
      "75.0% 완료\n",
      "76.0% 완료\n",
      "77.0% 완료\n",
      "78.0% 완료\n",
      "79.0% 완료\n",
      "80.0% 완료\n",
      "81.0% 완료\n",
      "82.0% 완료\n",
      "83.0% 완료\n",
      "84.0% 완료\n",
      "85.0% 완료\n",
      "86.0% 완료\n",
      "87.0% 완료\n",
      "88.0% 완료\n",
      "89.0% 완료\n",
      "90.0% 완료\n",
      "91.0% 완료\n",
      "92.0% 완료\n",
      "93.0% 완료\n",
      "94.0% 완료\n",
      "95.0% 완료\n",
      "96.0% 완료\n",
      "97.0% 완료\n",
      "98.0% 완료\n",
      "99.0% 완료\n",
      "100.0% 완료\n",
      "calculating SVD ...\n",
      "\n",
      "[query] you\n",
      " i: 0.6643731594085693\n",
      " we: 0.6298354268074036\n",
      " somebody: 0.5481226444244385\n",
      " 've: 0.5429369211196899\n",
      " anybody: 0.5263148546218872\n",
      "\n",
      "[query] year\n",
      " earlier: 0.6180377006530762\n",
      " quarter: 0.615651547908783\n",
      " month: 0.6146007776260376\n",
      " last: 0.5919893383979797\n",
      " february: 0.5582573413848877\n",
      "\n",
      "[query] car\n",
      " luxury: 0.5959149599075317\n",
      " auto: 0.5834312438964844\n",
      " vehicle: 0.5332110524177551\n",
      " cars: 0.5145776867866516\n",
      " luxury-car: 0.5061354637145996\n",
      "\n",
      "[query] toyota\n",
      " motor: 0.6826269030570984\n",
      " motors: 0.6420280933380127\n",
      " nissan: 0.6312842965126038\n",
      " honda: 0.6233224868774414\n",
      " lexus: 0.5647585988044739\n"
     ]
    }
   ],
   "source": [
    "#PTB 데이터셋을 이용하여 통계기반 기법 평가\n",
    "#과정은 다음과 같음\n",
    "#1. 텍스트 데이를 전처리 하여 corpus 생성\n",
    "#2. corpus 이용 동시발생 행렬 생성\n",
    "#3. 동시발행 행렬 이용 PPMI행렬 생성\n",
    "#4. PPMI행렬을 차원축소한 U행렬 생성\n",
    "#5. U행렬 이용 단어들의 유사도 산출\n",
    "\n",
    "from mh_common.mh_utils import most_similar, create_co_matrix, ppmi\n",
    "\n",
    "window_size = 2 #맥락으로 참조할 주변 단어의 수\n",
    "wordvec_size = 100 #축소된 차원(단어)의 수\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train') #이과정안에 preprocess가 이미 포함되어 있음\n",
    "vocab_size = len(word_to_id)\n",
    "print('동시발생 수 계산 ...')\n",
    "C = create_co_matrix(corpus, vocab_size, window_size)\n",
    "print('PPMI 계산 ...')\n",
    "W = ppmi(C, verbose = True)\n",
    "\n",
    "print('calculating SVD ...')\n",
    "try:\n",
    "    from sklearn.utils.extmath import randomized_svd\n",
    "    U, S, V = randomized_svd(W, n_components = wordvec_size, n_iter = 5,\n",
    "                            random_state = None)\n",
    "except ImportError:\n",
    "    U, S, V = np.linalg.svd(W)\n",
    "    \n",
    "word_vecs = U[:, :wordvec_size]\n",
    "\n",
    "#검색할 단어들\n",
    "querys = ['you', 'year', 'car', 'toyota']\n",
    "for query in querys:\n",
    "    most_similar(query, word_to_id, id_to_word, word_vecs, top = 5)\n",
    "    #단어들을 검색하기 위해 참조되는 행렬이\n",
    "    #바로 차원이 축소된 행렬 U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
