{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#벡터와 행렬\n",
    "#책에서 벡터는 특별한 설명이 없다면 기본적으로 '행벡터'로 가정\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "x = np.array([1, 2, 3])\n",
    "\n",
    "x.__class__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.ndim #차원수를 알려주는 인스턴스 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = np.array([[1,2,3], [4,5,6]])\n",
    "W.shape #다차원 배열의 형상을 알려주는 인스턴스 변수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  3,  5],\n",
       "       [ 7,  9, 11]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬의 원소별 연산\n",
    "\n",
    "W = np.array([[1,2,3], [4,5,6]])\n",
    "X = np.array([[0,1,2], [3,4,5]])\n",
    "\n",
    "W + X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  2,  6],\n",
       "       [12, 20, 30]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W * X\n",
    "    #실제 행렬곱이 아닌 단순히 동일한 형태를 가지는\n",
    "    #행렬 내 원소들 간의 곱을 말함\n",
    "    #즉 1행 1열의 원소끼리의 곱 1 * 0을 말함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 20],\n",
       "       [30, 40]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#브로드캐스트\n",
    "#형상이 다른 배열들간의 연산수행\n",
    "\n",
    "#스칼라 연산\n",
    "A = np.array([[1,2], [3,4]])\n",
    "A * 10 #모든 원소들에 각 10을 곱해주는 연산 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10, 40],\n",
       "       [30, 80]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#저차원 행렬(혹은 벡터)와 다차원 행렬간의 연산\n",
    "A = np.array([[1,2], [3,4]])\n",
    "b = np.array([10, 20])\n",
    "\n",
    "A * b #b를 A의 각 행의 원소에 대응이 되게 연산을 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#벡터의 내적과 행렬곱\n",
    "\n",
    "#벡터의 내적, 차원이 같은 벡터들간의 대응된느 원소들의 곱을 모두 더한것\n",
    "\n",
    "a = np.array([1, 2, 3])\n",
    "b = np.array([4, 5, 6])\n",
    "\n",
    "np.dot(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[19, 22],\n",
       "       [43, 50]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#행렬 곱\n",
    "#n*p, p*m 행렬간에는 행렬곱 연산을 수행할 수 있다\n",
    "#즉 좌측 행렬의 열개수와 우측 행렬의 행의 개수가 같으면 행렬곱 연산이 가능하다 (형상 확인)\n",
    "#행렬곱은 대응되는 행과 열간의 내적 연산의 반복으로 이루어진다\n",
    "\n",
    "A = np.array([[1, 2], [3, 4]])\n",
    "B = np.array([[5, 6], [7, 8]])\n",
    "\n",
    "np.matmul(A,B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 신경망의 추론\n",
    "\n",
    "- 보통 신경망은 입력층 -> 은닉층 -> 출력층으로 구성\n",
    "- 은닉층의 개수 + 출력층으로 신경망의 층 개수를 N으로 놓게 된다\n",
    "- 만약 한개의 은닉층과 출력층이 존재한다면 이는 2층 신경망이다\n",
    "\n",
    "</br>\n",
    "\n",
    "- 은닉층은 입력층과 가중치의 곱으로 산출된다\n",
    "- 그런데 입력층과 가중치 모두 행렬형태로 이루어져있기 때문에\n",
    "- 은닉층은 결국 입력층과 가중치의 행렬곱으로 구성된다\n",
    "\n",
    "### 미니배치\n",
    "- 전체 M개의 케이스를 가진 입력에서 작은 단위 N으로 쪼개어\n",
    "- 그룹 단위로 반복학습을 진행하는 방식을 미니배치라고 함 (이 책에서 신경망의 학습 방식을 미니배치 방식으로 가정하고 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#은닉층 계산\n",
    "\n",
    "W1 = np.random.randn(2, 4) #가중치, 2행 4열\n",
    "b1 = np.random.randn(4) #편향, 1차원이기 때문에 데이터 개수(열의 개수)만 입력\n",
    "x = np.random.randn(10, 2) #입력, 10행 2열\n",
    "\n",
    "h = np.matmul(x, W1) + b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 4)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 신경망의 추론\n",
    "\n",
    "## 시그모이드 함수\n",
    "비선형 활성화함수\n",
    "## $\\sigma(x) = \\frac{1}{1 + exp^{(-x)}}$\n",
    "\n",
    "- 신경망에서 은닉층단계 활성함수로 사용됨\n",
    "- 임의의 실수를 x로 입력받아서 0 ~ 1사이의 실수로 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력뉴런 2개, 은닉층 뉴런 4개, 출력 뉴런 3개인 완전연결계층 구현\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "x = np.random.randn(10, 2)\n",
    "W1 = np.random.randn(2, 4) #입력 -> 출력층으로의 가중치\n",
    "b1 = np.random.randn(4)\n",
    "\n",
    "h = np.matmul(x, W1) + b1\n",
    "a = sigmoid(h) #활성함수에 적용하여 새로운 값으로 변환됨\n",
    "\n",
    "W2 = np.random.randn(4, 3) #은닉 -> 출력층으로의 가중치\n",
    "b2 = np.random.randn(3)\n",
    "\n",
    "s = np.matmul(a, W2) + b2 #최종 출력층"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.36642941,  1.21345255, -0.04184321],\n",
       "       [ 0.1474541 ,  1.1212155 , -0.10213209],\n",
       "       [ 0.45289077,  1.26563868, -0.01848381],\n",
       "       [ 0.0673938 ,  1.46607425, -0.20772511],\n",
       "       [ 0.17518471,  1.14983204, -0.09949579],\n",
       "       [ 0.47894306,  1.33680189, -0.02064771],\n",
       "       [ 0.28691421,  1.30633261, -0.09191165],\n",
       "       [ 0.20045355,  1.11043226, -0.08021412],\n",
       "       [ 0.37669922,  1.31203798, -0.0572678 ],\n",
       "       [ 0.13057626,  1.60882416, -0.21438407]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 순전파 구현하기\n",
    "\n",
    "### 책의 구현규칙\n",
    "\n",
    "1) 모든 계층은 forward()와 backward()메서드를 가진다\n",
    "2) 모든 계층은 인스턴스 변수인 params와 grads를 가진다\n",
    "\n",
    "**인스턴스 변수**     \n",
    "https://server-talk.tistory.com/213    \n",
    "- 클래스 안의 모든 메서드들이 사용할 수 있는 변수\n",
    "- 즉 어떤 메서드 안에서만 사용되는 것이 아닌 클래스 내부 전역에서 사용가능한 변수\n",
    "- self.name 이런 형식과 같이 앞에 self가 붙음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid 계층 구현\n",
    "\n",
    "class Sigmoid:\n",
    "    def __init__(self):\n",
    "        self.params = []\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affine 계층 구현\n",
    "# Affine계층은 완전연결계층의 변환을 담당\n",
    "# 즉 입력에 가중치를 곱하고 편향을 더하는 작업을 수행하는 계층\n",
    "\n",
    "class Affine:\n",
    "    def __init__(self, W, b): #가중치 W와 편향 b가 매개변수\n",
    "        self.params = [W, b]\n",
    "        \n",
    "    def forward(self, x):\n",
    "        W, b = self.params\n",
    "        out = np.matmul(x, W) + b\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 완전연결계층 구현방식\n",
    "\n",
    "## x &rarr; Affine &rarr; Sigmoid &rarr; Affine &rarr; S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2층 신경망을 구현하기\n",
    "\n",
    "class TwoLayerNet:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        I, H, O = input_size, hidden_size, output_size\n",
    "        #여기서 I, H, O는 모두 행벡터의 형식을 가짐\n",
    "        #중요한 것은 행의 개수가 아닌 차원의 개수만 입력하면 됨\n",
    "        \n",
    "        W1 = np.random.randn(I, H) #입력층, 은닉층의 벡터 개수를 차례대로 행과 열로 입력\n",
    "        b1 = np.random.randn(H)\n",
    "        W2 = np.random.randn(H, O) #은닉층, 출력층의 벡터 개수를 차례대로 행과 열로 입력\n",
    "        b2 = np.random.randn(O)\n",
    "        \n",
    "        #계층 생성, 인스턴스 변수\n",
    "        self.layers = [\n",
    "            Affine(W1, b1),\n",
    "            Sigmoid(),\n",
    "            Affine(W2, b2)\n",
    "        ]#layer하나마다 어떤 메서드를 시행할 것이기 때문에 리스트 형태로 담음\n",
    "        \n",
    "        #가중치를 리스트에 모은다\n",
    "        self.params = []\n",
    "        for layer in self.layers: #layer안에 있는 Affine, Sigmoid 클래스를 하나씩 받아서\n",
    "            self.params += layer.params\n",
    "            #모든 층의 매개변수들을 저장하는 작업\n",
    "            #나중에 역전파를 통해서 가중치 갱신작업을 수행할 때도 유용함\n",
    "    \n",
    "    def predict(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer.forward(x)\n",
    "        return x\n",
    "    \n",
    "    #클래스 작동순서\n",
    "    #사용자가 입력층, 은닉층, 출력층의 크기를 입력하면\n",
    "    #W1, W2, b1, b2인 지역변수가 생성되고\n",
    "    #생성된 지역변수는 layers라는 리스트에 Affine, Sigmoid의 매개변수로 사용된다\n",
    "    #Affine, Sigmoid 클래스를 생성한다\n",
    "    \n",
    "    #layers안에 있는 클래스 하나마다 가지는 매개변수들인 W, b를\n",
    "    #인스턴스 변수인 params리스트 안에 하나씩 저장한다\n",
    "    \n",
    "    #predict 메서드를 통해서 추론을 실시한다\n",
    "    #층 하나마다 forward를 수행하여 입력 x를 변환하고\n",
    "    #변환된 x를 다음층에 입력으로 다시 넘겨서 이를 가지고 매개변수인 w,b를가지고 변환작업을 하는\n",
    "    #forward 메서드를 실행시켜 준다\n",
    "    #최종적으로 산출되는 x는 출력층의 값인 s이다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38589206,  1.07216422,  0.63124712],\n",
       "       [-1.57100104,  3.02389019, -0.17309472],\n",
       "       [-1.48625754,  1.89256693,  0.40146721],\n",
       "       [-2.09480412,  1.13971909,  0.68720784],\n",
       "       [-1.85917841,  2.70064855, -0.15736632],\n",
       "       [-0.55467461,  1.71551455,  0.88576475],\n",
       "       [-1.99416471,  1.46650742,  0.49699484],\n",
       "       [-1.96699781,  2.99137374, -0.36060949],\n",
       "       [-1.23041117,  2.64583157,  0.16197614],\n",
       "       [-0.87476224,  1.54665188,  0.8146635 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#구현한 2층 신경망 클래스를 바탕으로 추론을 수행\n",
    "\n",
    "x = np.random.randn(10, 2)\n",
    "model = TwoLayerNet(2, 4, 3)\n",
    "s = model.predict(x)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.63153068,  0.17269956, -1.46093523,  1.30715348],\n",
       "        [ 0.07966625,  0.23713848, -2.21927096,  0.34118326]]),\n",
       " array([-0.84429827, -0.21126253, -0.30847466, -1.11340769]),\n",
       " array([[ 0.56230142, -0.42875064,  1.03271061],\n",
       "        [ 1.77560308,  2.15301816, -0.35264404],\n",
       "        [-1.01831565,  1.9038966 , -1.26834299],\n",
       "        [-2.16612373, -0.93095482,  0.15748772]]),\n",
       " array([-1.41892522,  0.70643329,  0.64791639])]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
