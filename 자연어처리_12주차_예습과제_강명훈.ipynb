{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNNLM 개선 작업\n",
    "\n",
    "1) LSTM 계층을 깊게 쌓기\n",
    "- 연구자가 처한 텍스트 문제의 성격과 데이터 양에 따라서 LSTM 층을 깊게 쌓는 것이 정확도 향상에 도움을 줄 수 있음\n",
    "- 층을 깊게 쌓는 것은 **모델의 표현력**을 향상 시키는 것이라고도 할 수 있음\n",
    "- 층의 개수를 설정하는 것 또한 하이퍼 파라미터에 해당됨 -> 적절히 설정하는 것이 하나의 과업\n",
    "\n",
    "2) Dropout\n",
    "- 사용자가 설정한 뉴런의 비율만큼 무작위로 무시하고 학습을 진행하는 **정규화 방법**\n",
    "- 정규화는 모델의 일반화 능력을 향상시키고 과적합 문제를 회피하기 위함임\n",
    "- 일반적인 Dropuout :\n",
    "    - RNN, LSTM에서 Dropout을 구현하기 위해서는 시간방향에 Dropuout Layer를 적용하지 않고 동일한 시간t 내의 상, 하위 계층 사이에 Dropout 계층을 쌓는방식을 이용\n",
    "- 변형 Dropout :\n",
    "    - RNN, LSTM에서 시간방향 및 계층 방향 모두에 Dropout Layer를 적용한느 방법. 이를 구현하기 위해서 MASK를 도입했는데 이는 동일한 계층에 있는 Dropuout Layer, 시간방향에 진행되는 Dropuout Layer별로 동일한 뉴런들을 MASK하여 나머지 층은 그대로 학습이 진행되도록 하는 방법\n",
    "    \n",
    "3) Weight Tying (가중치 공유)\n",
    "- Embedding 계층의 가중치 **V * H** 와 Affine 꼐층의 가중치 **H * V**를 하나의 가중치로 동일하게 공유하도록 하는 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2층 LSTM과 Dropout, Weight Tying 기법을 적용한 BetterRnnlm 구현\n",
    "import numpy as np\n",
    "from mh_common.mh_time_layers import *\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'C:\\Users\\myunghoon_k\\OneDrive - UOS\\bitamin\\dl_nlp_study\\deep-learning-from-scratch-2-master')\n",
    "from common.base_model import BaseModel\n",
    "\n",
    "class BetterRnnlm(BaseModel):\n",
    "    \n",
    "    def __init__(self, vocab_size = 10000, wordvec_size = 650,\n",
    "                hidden_size = 650, dropout_ratio = 0.5):\n",
    "        V, D, H = vocab_size, wordvec_size, hidden_size\n",
    "        rn = np.random.randn\n",
    "        \n",
    "        embed_W = (rn(V, D) / 100).astype('f')\n",
    "        lstm_Wx1 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh1 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b1 = np.zeros(4*H).astype('f')\n",
    "        lstm_Wx2 = (rn(D, 4*H) / np.sqrt(D)).astype('f')\n",
    "        lstm_Wh2 = (rn(H, 4*H) / np.sqrt(H)).astype('f')\n",
    "        lstm_b2 = np.zeros(4*H).astype('f')\n",
    "        affine_b = np.zeros(V).astype('f')\n",
    "        \n",
    "        self.layers = [\n",
    "            TimeEmbedding(embed_W),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx1, lstm_Wh1, lstm_b1, stateful = True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeLSTM(lstm_Wx2, lstm_Wh2, lstm_b2, stateful = True),\n",
    "            TimeDropout(dropout_ratio),\n",
    "            TimeAffine(embed_W.T, affine_b)\n",
    "        ]\n",
    "        \n",
    "        self.loss_layer = TimeSoftmaxWithLoss()\n",
    "        self.lstm_layers = [self.layers[2], self.layers[4]]\n",
    "        self.drop_layers = [self.layers[1], self.layers[3], self.layers[5]]\n",
    "        \n",
    "        self.params, self.grads = [], []\n",
    "        for layer in self.layers:\n",
    "            self.params += layer.params\n",
    "            self.grads += layer.grads\n",
    "            \n",
    "    def predict(self, xs, train_flg = True):\n",
    "        for layer in self.drop_layers:\n",
    "            layer.train_flg = train_flg\n",
    "            \n",
    "        for layer in self.layers:\n",
    "            xs = layer.forward(xs)\n",
    "        return xs\n",
    "    \n",
    "    def forward(self, xs, ts, train_flg = True):\n",
    "        score = self.predict(xs, train_flg)\n",
    "        loss = self.loss_layer.forward(score, ts)\n",
    "        return loss\n",
    "    \n",
    "    def backward(self, dout = 1):\n",
    "        dout = self.loss_layer.backward(dout)\n",
    "        for layer in reversed(self.layers):\n",
    "            dout = layer.backward(dout)\n",
    "        return dout\n",
    "    \n",
    "    def reset_state(self):\n",
    "        for layer in self.lstm_layers:\n",
    "            layer.reset_state()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| 에폭 1 |  반복 1 / 1327 | 시간 1[s] | 퍼플렉서티 10000.32\n",
      "| 에폭 1 |  반복 21 / 1327 | 시간 39[s] | 퍼플렉서티 2386.54\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-655434a8595a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     trainer.fit(xs, ts, max_epoch = 1, batch_size = batch_size,\n\u001b[1;32m---> 44\u001b[1;33m                time_size = time_size, max_grad = max_grad)\n\u001b[0m\u001b[0;32m     45\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - UOS\\bitamin\\dl_nlp_study\\deep-learning-from-scratch-2-master\\common\\trainer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, xs, ts, max_epoch, batch_size, time_size, max_grad, eval_interval)\u001b[0m\n\u001b[0;32m    109\u001b[0m                 \u001b[1;31m# 기울기를 구해 매개변수 갱신\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_t\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m                 \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m                 \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_duplicate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# 공유된 가중치를 하나로 모음\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mmax_grad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-97879e8089c4>\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m     58\u001b[0m         \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_layer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mreversed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mdout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - UOS\\bitamin\\dl_nlp_study\\mh_common\\mh_time_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    138\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m             \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdout\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m             \u001b[0mgrad\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive - UOS\\bitamin\\dl_nlp_study\\mh_common\\mh_layers.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, dout)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[0mdW\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mdW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;31m#for i, word_id in enumerate(self.idx):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#모델 학습과정 구현\n",
    "#Pytorch 에서 제공하는 기능을 추가하여 구현하기\n",
    "#Epoch마다 Validation 과정에서 perplexity가 낮아질 경우 lr을 이전보다 낮추는 기능을 추가하기\n",
    "from common import config\n",
    "\n",
    "config.GPU = True\n",
    "\n",
    "from mh_common.mh_optimizer import SGD\n",
    "from common.trainer import RnnlmTrainer\n",
    "from common.util import eval_perplexity, to_gpu\n",
    "from dataset import ptb\n",
    "\n",
    "#하이퍼 파라미터 설정\n",
    "batch_size = 20\n",
    "wordvec_size = 650\n",
    "hidden_size = 650\n",
    "time_size = 35\n",
    "lr = 20.0\n",
    "max_epoch = 40\n",
    "max_grad = 0.25\n",
    "dropout = 0.5\n",
    "\n",
    "#데이터 읽기\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "corpus_val, _, _ = ptb.load_data('val')\n",
    "corpus_test, _, _ = ptb.load_data('test')\n",
    "\n",
    "if config.GPU:\n",
    "    corpus = to_gpu(corpus)\n",
    "    corpus_val = to_gpu(corpus_val)\n",
    "    corpus_test = to_gpu(corpus_test)\n",
    "    \n",
    "vocab_size = len(word_to_id)\n",
    "xs = corpus[:-1]\n",
    "ts = corpus[1:]\n",
    "\n",
    "model = BetterRnnlm(vocab_size, wordvec_size, hidden_size, dropout)\n",
    "optimizer = SGD(lr)\n",
    "trainer = RnnlmTrainer(model, optimizer)\n",
    "\n",
    "best_ppl = float('inf')\n",
    "for epoch in range(max_epoch):\n",
    "    trainer.fit(xs, ts, max_epoch = 1, batch_size = batch_size,\n",
    "               time_size = time_size, max_grad = max_grad)\n",
    "    \n",
    "    model.reset_state()\n",
    "    ppl = eval_perplexity(model, corpus_val)\n",
    "    print('검증 퍼플렉서티: ', ppl)\n",
    "    \n",
    "    if best_ppl > ppl:\n",
    "        best_ppl = ppl\n",
    "        model.save_params()\n",
    "    else:\n",
    "        lr /= 4.0\n",
    "        optimizer.lr = lr\n",
    "        \n",
    "    model.reset_state()\n",
    "    print('-' * 50)\n",
    "    \n",
    "#테스트 데이터로 평가\n",
    "model.reset_state()\n",
    "ppl_test = eval_perplexity(mdoel, corpus_test)\n",
    "print('테스트 퍼플렉서티: ', ppl_test)\n",
    "#어쩐 일인지 GPU로 학습이 되지 않음, Cupy는 정상작동함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(929588,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN을 이용한 문장 생성\n",
    "\n",
    "- 기존의 RNN모델은 학습을 한 뒤 Softmax 계층에서 확률표현을 하여 input다음에 등장할 단어를 맞추는 작업을 수행\n",
    "- 이를 바탕으로 input문장이 주어지면 output 문장을 생성하는 모델을 개발하는 작업을 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mh_common.mh_functions import softmax\n",
    "from ch06.rnnlm import Rnnlm\n",
    "from ch06.better_rnnlm import BetterRnnlm\n",
    "\n",
    "class RnnlmGen(Rnnlm):\n",
    "    def generate(self, start_id, skip_ids = None, sample_size = 100):\n",
    "        word_ids = [start_id]\n",
    "        \n",
    "        x = start_id\n",
    "        \n",
    "        while len(word_ids) < sample_size:\n",
    "            x = np.array(x).reshape(1, 1)\n",
    "            score = self.predict(x) #RNN층을 통해 학습된 분산표현이 표현된 어떤 값들\n",
    "            p = softmax(score.flatten()) #분산표현이 softmax층을 통해 확률표현으로 정규화됨\n",
    "            \n",
    "            sampled = np.random.choice(len(p), size = 1, p = p)\n",
    "            if (skip_ids is None) or (sampled not in skip_ids):\n",
    "                x = sampled\n",
    "                word_ids.append(int(x))\n",
    "                \n",
    "        return word_ids\n",
    "    \n",
    "    def get_state(self):\n",
    "        return self.lstm_layer.h, self.lstm_layer.c\n",
    "    \n",
    "    def set_state(self, state):\n",
    "        self.lstm_layer.set_state(*state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#위의 모델로 문장 생성하기\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from dataset import ptb\n",
    "\n",
    "corpus, word_to_id, id_to_word = ptb.load_data('train')\n",
    "vocab_size = len(word_to_id)\n",
    "corpus_size = len(corpus)\n",
    "\n",
    "model = RnnlmGen()\n",
    "model.load_params(r\"C:\\Users\\myunghoon_k\\OneDrive - UOS\\bitamin\\dl_nlp_study\\deep-learning-from-scratch-2-master\\ch06\\Rnnlm.pkl\")\n",
    "\n",
    "# start 문자와 skip 문자 설정\n",
    "start_word = 'you' #첫문자를 you로 설정하여 이 뒤에 올 단어들을 예측\n",
    "start_id = word_to_id[start_word]\n",
    "skip_words = ['N', '<unk>', '$']\n",
    "skip_ids = [word_to_id[w] for w in skip_words]\n",
    "\n",
    "# 문장 생성\n",
    "word_ids = model.generate(start_id, skip_ids)\n",
    "txt = ' '.join([id_to_word[i] for i in word_ids])\n",
    "txt = txt.replace(' <eos>', '.\\n')\n",
    "print(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## seq2seq 모델\n",
    "\n",
    "- sequence to sequence, 즉 시계열 데이터를 받아서 비슷한 형태의 시계열 데이터를 생산하는 모델\n",
    "- Encoder, Decoder를 모델의 주요구조로 가지며 이 Encoder, Decoder는 각각 RNN형태의 모델로 구성된다\n",
    "- Encoder\n",
    "    - input을 받아서 Embedding -> LSTM층으로 보내는 작업을 수행\n",
    "    - 이전의 Rnnlm, BetterRnnlm은 다음시점의 계층 및 상위 계층으로 h를 보냈으나\n",
    "    - Encoder내에서는 **상위 계층이 존재하지 않으므로** 다음 t 시점으로만 h를 보냄\n",
    "    - 또한 LSTM구조상 cell state output이 생성되게 되는데 이는 오직 Encoder내부 학습에서만 사용되며 Decoder로는 전달되지 않는다\n",
    "    - 따라서 최종 Encoder input의 h만이 **Decoder의 추가적인 input**으로 사용되게 됨\n",
    "    \n",
    "### h를 Decoder를 보내는 것은 input의 정보를 응축하여 보내는것으로 이해할 수 있음\n",
    "### 즉 가변길이의 input정보들을 h라는 고정길이 벡터로 변환하여 보내는 것\n",
    "    \n",
    "- Decoder\n",
    "    - 정답에 해당하는 시계열 데이터를 input으로, Encoder의 최종 h를 또 다른 input으로 사용하여 번역될 단어를 예측\n",
    "    - 모델 구조는 Rnnlm, BetterRnnlm과 비슷한데, Embedding -> LSTM(여러개 존재 가능) -> Affine -> Softmax 구조를 취함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seq2seq의 Toy Problem\n",
    "#문자열 형태로 된 수식을 학습하여 결과를 내는 모델 만들기\n",
    "#즉 수식에 대한 사전 규칙 부여 없이 딥러닝 모델로 스스로 수식의 규칙을 학습하도록 하는 것\n",
    "\n",
    "from dataset import sequence\n",
    "\n",
    "(x_train, t_train), (x_test, t_test) = sequence.load_data('addition.txt', seed = 1984)\n",
    "\n",
    "char_to_id, id_to_char = sequence.get_vocab()\n",
    "\n",
    "print(x_train.shape, t_train.shape)\n",
    "print(x_test.shape, t_test.shape)\n",
    "\n",
    "print(x_train[0]) #숫자 문자열의 id가 담긴형태로 데이터가 구성되어 있음\n",
    "print(x_test[0])\n",
    "\n",
    "print(''.join([id_to_char[c] for c in x_train[0]]))\n",
    "print(''.join([id_to_char[c] for c in t_train[0]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_mh",
   "language": "python",
   "name": "torch_mh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
